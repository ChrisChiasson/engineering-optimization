<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="Line_Search"
	xmlns="http://docbook.org/ns/docbook"
	xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:xl="http://www.w3.org/1999/xlink"
	xmlns:xml="http://www.w3.org/XML/1998/namespace"
	version="5">
	<title>Line Search &#x2014; Project 1</title>
	<para><xref linkend="pr_1_screenshot_assignment"/> and
		<xref linkend="pr_1_screenshot_flow_chart"/> below show our first
		project	as assigned by Dr. Mohamed El-Sayed.</para>
	<figure xml:id="pr_1_screenshot_assignment">
		<title>Project 1 Assignment</title>
			<screenshot>
				<mediaobject>
					<imageobject role="html">
						<imagedata
							fileref="mout/pr_1_screenshot_assignment.png"/>
					</imageobject>
					<imageobject role="fo">
						<imagedata contentwidth="5in"
							fileref="mout/pr_1_screenshot_assignment.png"/>
					</imageobject>
					<textobject>
						<phrase>Project 1: (25% of class grade) due 6th week
							Develop	a single variable unconstrained minimization
							routine	using the bounding-golden section-quad fit
							chart developed in class. Test the program using
							first (a) F(x)=(x-10)^2 (b) *2nd use the program to
							solve the example 2-1 problem Required: (1) The
							program (2) Documentation of all the variables and
							flowcharts (3) The output of the 2 problems (test
							cases)</phrase>
					</textobject>
				</mediaobject>
			</screenshot>
		<caption>
			<para>This is a video screen capture from the beginning of the
				third session showing our line search assignment.</para>
		</caption>
	</figure>
	<figure xml:id="pr_1_screenshot_flow_chart">
		<title>Project 1 Flowchart</title>
		<screenshot>
			<mediaobject>
				<imageobject role="html">
					<imagedata fileref="mout/pr_1_screenshot_flow_chart.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata contentwidth="5in"
						fileref="mout/pr_1_screenshot_flow_chart.png"/>
				</imageobject>
				<textobject>
					<phrase>This diagram is a code flowchart for the Project 1
						routine for finding a bounded minimum.</phrase>
				</textobject>
			</mediaobject>
		</screenshot>
		<caption>
			<para>This video screen capture contains the flowchart that goes
				with the first capture in this session. It references
				two figures in <citation><olink targetdoc="self" targetptr="GNVNOTED"/></citation>.
				Figure 2-11 contains a method for bounding a minimum. Figure 2-8
				details a four point golden section method. The chart directs
				us to bound the minimum, perform the golden section method,
				and then to curve fit the point for the last evaluation, while
				keeping	track of all function evaluations.</para>
		</caption>
	</figure>
	<para>As <xref linkend="pr_1_screenshot_assignment"/> shows, I am to create
		a procedure for solving single-variable unconstrained minimization
		problems. This is also referred to as a line search, since there is
		only one independant variable.</para>
	<para>The line search description follows in section XXX. I use the routine
		to solve the requested problems in section XXX.</para>
	<section xml:id="Description_of_Line_Search">
		<title>Description of Line Search</title>
		<para>In order to satisfy constraints in later assignments, I
			eventually implemented a slightly different routine than that
			recommended in <xref linkend="pr_1_screenshot_flow_chart"/>.
			The reason for this is that the routine from the class notes does
			not provide for	convergence to a given tolerance. The notes simply
			indicate that we should use a fixed number of iterations of the
			golden section method, and then use inverse polynomial interpolation
			to find the	final abscissa. That method would at least guarantee a
			certain	factor of reduction of the initial bracketing interval, but
			there is very little assurance that the algorithm would converge. To
			make matters worse, some of the routines for multidimensional
			optimization that eventually depend on the line search routine
			need a nearly exact line search to behave properly.</para>
		<para>One way to obtain convergence would be to exclusively use the
			golden section routine. I have tried this, and the number of
			function evaluations required is excessive. In addition, it does not
			involve interpolation, so I feel it would violate the spirit of the
			assignment.</para>
		<para>So, I implemented Brent's method after reading the description in
			NUMERICAL RECIPES. I use inverse polynomial	interpolation and the
			golden section method. The method is usually able to converge much
			faster than the golden section method alone. SECTION BLAH has more
			information about the line search convergence.</para>
		<para>My bracketing routine is the same as the one given in class. It
			proceeds in a downhill direction until finding three points where
			the middle point has a lower ordinate than the other two. SECTION
			BLAH has more information about the line search bracketing.</para>
		<para>Even though flow charts were only requested for the bracketing
			and convergence routines, I provided an overall flow chart for the
			line search in APPENDIX SECTION BLAH. In addition, the entire
			SOURCE CODE FOR THIS ROUTINE IS AVAILABLE HERE.</para>
		<section xml:id="Calling_the_Line_Search">
			<title>Calling the Line Search</title>
			<para>The line search is called as follows from within Mathematica:
				<command>FindMinimum[f,{x,xleft,xright},Method&#8594;"Unimodal"]</command><footnote>
				<para>I have written this function three times. It was
					originally called FindUnimodalMinimum. Problems with the
					later constrained multidimensional optimization assignments
					prompted me to reprogram all my code from the top-down.
					While I was reprogramming, I used Mathematica's FindMinimum
					routine to handle the low-level line search. So, when I was
					ready to rewrite this routine again, I made it mostly
					conform to the calling style of FindMinimum, but it executes
					my code	when the option	Method&#8594;"Unimodal" is passed. This
					is important, because if one leaves off the Method
					statement, one of the built in methods, "Gradient",
					"ConjugateGradient", "QuasiNewton", "Newton", or 
					"LevenbergMarquardt", will be chosen automatically.</para></footnote>.
					Its variable list follows. A simple example of this calling
					structure is given in SIMPLE EXAMPLE.</para>
				<variablelist>
					<varlistentry>
						<term>f</term>
						<listitem>
							<para>f is a function of the independant variable,
								x in this case.</para>
						</listitem>
					</varlistentry>
					<varlistentry>
						<term>x</term>
						<listitem>
							<para>x is the independant variable in f.</para>
						</listitem>
					</varlistentry>
					<varlistentry>
						<term>xleft</term><term>xright</term>
						<listitem>
							<para>xleft and xright must be numbers such that
								<inlineequation><mathphrase>xleft &lt; xright</mathphrase></inlineequation>.
								They are the initial interval endpoints for the
								bracketing step.</para>
						</listitem>
					</varlistentry>
					<varlistentry>
						<term>Method</term>
						<listitem>
							<para>Method is an option that can be changed
								with a rule such as Method&#8594;"Unimodal".
								Using that rule causes Mathematica to execute my
								unimodal line search.</para>
						</listitem>
					</varlistentry>
				</variablelist>
		</section>
		<section xml:id="Bracketing">
			<title>Bracketing</title>
			<para>bracketing</para>
		</section>
	</section>
</chapter>